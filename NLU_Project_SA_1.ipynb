{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLU_project_SA",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ-YyCcWjKMF",
        "outputId": "abafe6a6-90e6-4a99-fa46-9354191812ca"
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (56.1.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jUTisRPkKFr"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "Text = data.Field(tokenize = 'spacy', tokenizer_language = 'en_core_web_sm')\n",
        "\n",
        "Label = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r2J-EmDkVVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3c56caf-c0e3-448e-f463-28fd62bdf05a"
      },
      "source": [
        "#The following code automatically downloads the IMDb dataset and splits it into the canonical train/test splits as torchtext.datasets objects\n",
        "from torchtext.legacy import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(Text, Label)\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(Text, Label)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz:   1%|          | 590k/84.1M [00:00<00:16, 5.10MB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 80.0MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldMJ-Mg1kiEB",
        "outputId": "2da39a64-5fd1-407c-ea6c-8d4f8431d210"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV-CKtZMku0J",
        "outputId": "6bf98903-e8ba-4b79-b243-bc230f10da2e"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['To', 'finally', 'see', 'what', 'many', 'consider', 'to', 'be', 'the', 'greatest', 'women', '-', 'in', '-', 'prison', 'film', 'of', 'all', 'time', ',', 'I', 'felt', 'like', 'I', 'had', 'accomplished', 'something', 'as', 'ridiculous', 'as', 'that', 'sounds', '.', 'Boy', ',', 'it', 'sure', 'contained', 'the', 'elements', 'I', 'expected', ',', 'and', 'delivered', 'so', 'much', 'more', '.', 'A', 'constant', 'I', \"'m\", 'discovering', 'in', 'these', 'films', 'is', 'the', 'toughness', 'and', 'grit', 'of', 'the', 'actresses', 'in', 'the', 'roles', 'of', 'prisoners', 'preparing', 'for', 'escape', 'while', 'their', 'threshold', ',', 'tolerance', ',', 'and', 'resolve(', '..', 'not', 'to', 'mention', 'sanity)being', 'tested', 'by', 'their', 'superiors', '.', 'While', 'most', 'of', 'them', 'were', 'hired', 'for', 'the', 'way', 'they', 'look', 'naked', ',', 'because', 'the', 'nature', 'of', 'the', 'genre', 'demands', 'such', 'gratuitous', 'elements', ',', 'something', 'else', 'emerges', ',', 'other', 'attributes', ',', 'such', 'as', 'attitude', 'and', 'guts', ',', 'that', 'I', 'ultimately', 'respond', 'to.<br', '/><br', '/>This', ',', 'as', 'you', 'may', 'know', 'all', 'too', 'well', ',', 'was', 'Demme', \"'s\", 'debut', 'for', 'his', 'mentor', 'Roger', 'Corman', ',', 'and', 'he', 'provides', 'the', 'target', 'audience', 'with', 'exactly', 'what', 'they', 'desire', 'while', 'putting', 'his', 'own', 'stamp', 'on', 'the', 'proceedings', '.', 'For', 'instance', ',', 'there', 'are', 'bizarre', 'dreams', 'certain', 'characters', 'have', 'which', 'define', 'their', 'current', 'psychological', 'states(', '..', 'there', \"'s\", 'a', 'particular', 'number', 'featuring', 'warden', 'Barbara', 'Steele', 'where', 'she', 'reminded', 'me', 'of', 'Alex', 'de', 'Large', 'of', 'A', 'Clockwork', 'Orange).<br', '/><br', '/>The', 'film', 'has', 'female', 'prisoners', 'planning', 'a', 'daring', 'escape', ',', 'tired', 'of', 'the', 'crazed', 'antics', 'of', 'their', 'wheel', '-', 'chair', 'bound', 'warden', 'and', 'her', 'nutty', 'prison', 'doc', ',', 'Randolph(Warren', 'Miller', ')', '.', 'Juanita', 'Brown', 'is', 'Maggie', ',', 'the', 'tough', ',', 'sassy', 'sister', 'who', 'is', 'fed', 'up', 'with', 'the', 'environment', 'and', 'will', 'do', 'whatever', 'it', 'takes', 'to', 'get', 'out', '.', 'She', \"'s\", 'the', 'one', 'all', 'the', 'girls', 'fear', 'to', 'cross', '.', 'Erica', 'Gavin', 'is', 'Jacqueline', 'Wilson', ',', 'the', 'newest', 'prisoner', 'who', 'was', 'busted', 'by', 'police', 'and', 'sentenced', 'for', 'the', 'murder', 'of', 'a', 'cop', ',', 'unwilling', 'to', 'give', 'up', 'the', 'names', 'of', 'those', 'she', 'was', 'involved', 'with', '.', 'Roberta', 'Collins', 'is', 'Belle', ',', 'a', 'serial', 'kleptomaniac', ',', 'best', 'pals', 'with', 'Pandora(Ella', 'Reid', ')', '.', 'Belle', 'becomes', 'the', 'obsession', 'of', 'Randolph', 'who', 'promises', 'Superintendent', 'McQueen(Steele)that', 'through', 'a', 'surgical', 'procedure', 'he', 'can', 'remove', 'her', 'violent', 'tendencies', '.', 'Drugging', 'her', 'up', ',', 'Randolph', 'takes', 'nude', 'pictures', 'and', 'sodomizes', 'her', ',', 'whimpering', 'like', 'a', 'little', 'girl', 'due', 'to', 'his', 'own', 'mental', 'deficiencies', 'while', 'hugging', 'her', 'naked', 'body', 'in', 'his', 'arms', '.', 'Cheryl', 'Rainbeaux', 'Smith', 'is', 'Lavelle', ',', 'in', 'prison', 'for', 'life', 'for', 'murdering', 'a', 'scumbag', 'whose', 'relative', 'was', 'a', 'Senator', '.', 'Lavelle', 'receives', 'work', 'in', 'Randolph', \"'s\", 'office', 'and', 'is', 'the', 'one', 'responsible', 'for', 'relating', 'his', 'dirty', 'antics', 'to', 'Pandora', '.', 'Demme', 'effectively', 'builds', 'the', 'movie', 'to', 'the', 'expected', 'finale', 'as', 'a', 'planned', 'break', '-', 'out', ',', 'using', 'those', 'behind', 'the', 'various', 'traumas', 'inflicted', 'on', 'the', 'prisoners', 'as', 'hostages', ',', 'with', 'gunfire', 'erupting.<br', '/><br', '/>I', 'was', 'quite', 'impressed', 'with', 'the', 'photographic', 'work', 'of', 'long', 'time', 'Demme', 'collaborator', ',', 'cinematographer', 'Tak', 'Fujimoto', ',', 'as', 'he', 'is', 'able', 'to', 'establish', 'some', 'visually', 'arresting', 'moments', 'within', 'the', 'cramped', 'confines', 'of', 'the', 'prison', ',', 'cells', 'and', 'rooms', ',', 'not', 'an', 'easy', 'task', '.', 'The', 'prison', 'is', 'appropriately', 'crummy', 'and', 'the', 'girls', ',', 'despite', 'being', 'quite', 'attractive', ',', 'look', 'the', 'part', 'of', 'desperate', 'inmates', 'longing', ',', 'yearning', 'from', 'the', 'very', 'pits', 'of', 'their', 'souls', ',', 'to', 'escape', 'such', 'horrid', 'entrapment', '.', 'Steele', 'is', 'superb', 'as', 'the', 'warden', ',', 'understanding', 'how', 'to', 'take', 'the', 'role', 'close', 'to', 'the', 'brink', 'without', 'going', 'to', 'far', ',', 'candidly', 'able', 'to', 'express', 'the', 'madness', 'of', 'her', 'repressed', 'character', 'within', 'a', 'restraint', '..', 'notice', 'how', 'she', 'works', 'her', 'glasses', 'and', 'settles', 'herself', 'without', 'blowing', 'her', 'top', 'particularly', 'when', 'certain', 'behaviors', 'she', 'has', 'contempt', 'for', 'push', 'her', 'teetering', 'to', 'the', 'edge', '.', 'Cale', \"'s\", 'bluesy', 'score', 'is', 'incredibly', 'depressing', ',', 'while', 'also', 'casting', 'a', 'wink', 'to', 'the', 'audience', 'that', 'the', 'movie', 'is', 'still', 'fun', '-', 'and', '-', 'games', '..', 'I', 'think', 'Cale', \"'s\", 'score', 'mirrors', 'Demme', \"'s\", 'handling', 'of', 'the', 'material', '.', 'Cale', 'and', 'Demme', \"'s\", 'partnership', 'is', 'an', 'uncanny', 'alliance', 'that', 'presents', 'the', 'setting', 'as', 'a', 'sad', ',', 'isolating', ',', 'oppressive', 'place', ',', 'while', ',', 'almost', 'simultaneously', ',', 'showcasing', 'a', 'humorous', 'tone', 'that', 'permeates', 'due', 'to', 'the', 'colorful', 'characters', 'thanks', 'in', 'part', 'to', 'the', 'personalities', 'of', 'the', 'cast', '.', 'My', 'favorite', 'scene', 'happens', 'outside', 'the', 'prison', ',', 'as', 'two', 'of', 'our', 'girls(', '..', 'joining', 'forces', 'with', 'a', 'third)interrupt', 'a', 'bank', 'robbery', 'already', 'in', 'progress', '..', 'the', 'kicker', 'is', 'it', 'was', 'a', 'bank', 'they', 'were', 'planning', 'to', 'rob', '!', 'As', 'you', 'might', 'expect', ',', 'you', 'get', 'naked', 'women', 'in', 'showers', ',', 'prisoner', 'in', 'solitary', ',', 'a', 'cat', 'fight', ',', 'shootouts', ',', 'attempted', 'escapes', 'which', 'go', 'awry', ',', 'and', 'other', 'exploitative', 'elements(', '..', 'such', 'as', 'a', 'horrifying', 'shock', 'therapy', 'session', ',', 'not', 'to', 'exclude', 'the', 'shocking', 'aforementioned', 'sequence', 'where', 'the', 'screwy', 'doc', 'takes', 'advantage', 'of', 'Belle', ')', '.', 'Interesting', 'enough', ',', 'Demme', 'relates', 'the', 'film', 'to', 'the', 'audience', 'without', 'a', 'whiff', 'of', 'pretension', ',', 'understanding', 'exactly', 'the', 'kind', 'of', 'movie', 'he', 'was', 'making', '.'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfBhCU6yk-Rh"
      },
      "source": [
        "import random \n",
        "\n",
        "train_data, val_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2anc9LLlsXx",
        "outputId": "586bd67d-8266-4d46-9721-29d305085de8"
      },
      "source": [
        "print(f\"Number of Traning example: {len(train_data)}\")\n",
        "print(f\"Number of Validation example: {len(val_data)}\")\n",
        "print(f\"Number of Testing example: {len(test_data)}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Traning example: 17500\n",
            "Number of Validation example: 7500\n",
            "Number of Testing example: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdxIk1iPmP-C"
      },
      "source": [
        "Max_Vocab_Size = 25_000\n",
        "\n",
        "Text.build_vocab(train_data, max_size = Max_Vocab_Size)\n",
        "Label.build_vocab(train_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTjWn19tm6Xe",
        "outputId": "9ecba7da-ed17-46b4-c230-5aef480cfff4"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(Text.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(Label.vocab)}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96LlZyxWm-Ke",
        "outputId": "440c9038-de9e-43f9-ca0b-859a3b2bbb90"
      },
      "source": [
        "#to check whihc is most commom words\n",
        "print(Text.vocab.freqs.most_common(20))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 202434), (',', 191486), ('.', 165285), ('a', 109359), ('and', 109277), ('of', 100782), ('to', 93524), ('is', 76351), ('in', 61225), ('I', 54232), ('it', 53664), ('that', 49264), ('\"', 44659), (\"'s\", 43164), ('this', 42454), ('-', 37317), ('/><br', 35633), ('was', 34935), ('as', 30466), ('with', 29838)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN2YSg7snZTi",
        "outputId": "07d805ef-8b30-4181-8e10-eb5347415d37"
      },
      "source": [
        "print(Text.vocab.itos[:10])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs0nKn3-nfKu",
        "outputId": "ad121992-0621-4563-df05-abebd9cc3cf5"
      },
      "source": [
        "print(Label.vocab.stoi)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(None, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPI2IEGgq97i"
      },
      "source": [
        "Batch_Size = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, val_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data), \n",
        "    batch_size = Batch_Size,\n",
        "    device = device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd0mV-kpng66"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "    self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, text):\n",
        "\n",
        "    embedded = self.embedding(text)\n",
        "    output,hidden = self.rnn(embedded)\n",
        "    assert torch.equal(output[-1,:,:],hidden.squeeze(0))\n",
        "\n",
        "    return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx7ApP8Tx0FJ"
      },
      "source": [
        "INPUT_dim = len(Text.vocab)\n",
        "EMBEDDING_dim = 100\n",
        "HIDDEN_dim= 256\n",
        "OUTPUT_dim = 1\n",
        "\n",
        "model = RNN(INPUT_dim, EMBEDDING_dim, HIDDEN_dim, OUTPUT_dim)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZZJfqa8z-Hj",
        "outputId": "cc18c07d-5b59-4c2c-bec7-e897b0d383d1"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,592,105 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ9qDowS0GXF"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkvAFo800OJn"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gcPu88z0bC6"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGfklS8S0iTv"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "\n",
        "    return acc"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-a0BPNA06SR"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()     \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEQGH7WV1mhG"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q0iir6c110l"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "  \n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amzyjkgz1_NQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59928dc8-a558-4c18-b8b8-8c08117a462b"
      },
      "source": [
        "NUM_epochs = 5\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(NUM_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    val_loss, val_acc = evaluate(model, val_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.86%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 50.47%\n",
            "Epoch: 02 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.21%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 50.65%\n",
            "Epoch: 03 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.87%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 49.77%\n",
            "Epoch: 04 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.39%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 50.75%\n",
            "Epoch: 05 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.88%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 49.79%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AILWjkWuyJL6",
        "outputId": "fae0222f-4551-458e-8a37-b05ab8a77eaf"
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.708 | Test Acc: 47.88%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}